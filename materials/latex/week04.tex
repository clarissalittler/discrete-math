\section{Week 4: Counting and Probability I}

\textit{Or: ``The surprisingly hard question of `how many?'''}

\subsection*{Reading}
Epp \S 9.1--9.4, 9.9.\\
\textbf{Category theory companion:} Weeks 4--5 (\texttt{category\_theory\_companion.pdf}).

\subsection*{Why Counting?}

Counting seems like it should be trivial---after all, you learned it before kindergarten. But counting \emph{correctly} when things get complicated is surprisingly tricky. How many 8-character passwords are possible? How many ways can you seat 10 people at a round table? How likely is it that two people in a class of 30 share a birthday?

These questions require systematic techniques, and getting them wrong has consequences: underestimate password strength and you get hacked; miscount arrangements and your combinatorial proof falls apart; miscalculate probabilities and you make bad decisions.

This week introduces the fundamental counting principles. They're deceptively simple---multiplication, addition, inclusion-exclusion---but applying them correctly takes practice.

\subsection*{Learning objectives}
\begin{itemize}
  \item Build sample spaces and events for basic probability models.
  \item Apply the multiplication rule to count outcomes.
  \item Apply the addition rule and inclusion--exclusion for two or more sets.
  \item Use the pigeonhole principle to force collisions.
  \item Count permutations and arrangements with restrictions.
\end{itemize}

\subsection*{Key definitions and facts}

\subsubsection*{Probability Basics}

\begin{definition}[Sample space and event]
A \textbf{sample space} $S$ is the set of all possible outcomes of an experiment. An \textbf{event} is a subset $E \subseteq S$. The event $E$ \textbf{occurs} if the actual outcome is in $E$.
\end{definition}

\begin{definition}[Probability (equally likely outcomes)]
If all outcomes in a finite sample space $S$ are equally likely, then for any event $E$:
\[
P(E) = \frac{|E|}{|S|} = \frac{\text{number of favorable outcomes}}{\text{number of possible outcomes}}
\]
\end{definition}

This is why counting matters for probability: if you can count the favorable outcomes and the total outcomes, you can compute probabilities. The challenge is counting correctly.

\begin{theorem}[Basic probability properties]
For any events $A, B$ in sample space $S$:
\begin{enumerate}
  \item $0 \leq P(A) \leq 1$ (probabilities are between 0 and 1)
  \item $P(S) = 1$ and $P(\emptyset) = 0$ (something happens; nothing is impossible)
  \item $P(A^c) = 1 - P(A)$ where $A^c = S \setminus A$ (complement rule)
  \item If $A \cap B = \emptyset$, then $P(A \cup B) = P(A) + P(B)$ (disjoint addition)
\end{enumerate}
\end{theorem}

\subsubsection*{The Fundamental Counting Principles}

\begin{theorem}[Multiplication rule (product rule)]
If a procedure can be broken into $k$ successive steps, where:
\begin{itemize}
  \item Step 1 can be done in $n_1$ ways
  \item Step 2 can be done in $n_2$ ways (regardless of step 1's outcome)
  \item $\ldots$
  \item Step $k$ can be done in $n_k$ ways
\end{itemize}
then the total number of ways to complete the procedure is $n_1 \times n_2 \times \cdots \times n_k$.
\end{theorem}

The key requirement is independence: the number of ways to do each step must not depend on the choices made in previous steps. If step 2 has different numbers of options depending on what you chose in step 1, you need to be more careful.

\begin{theorem}[Addition rule (sum rule)]
If a task can be done either by method $A$ (in $n_1$ ways) or by method $B$ (in $n_2$ ways), and the two methods are mutually exclusive (no overlap), then the total number of ways is $n_1 + n_2$.
\end{theorem}

\begin{theorem}[Inclusion-exclusion (two sets)]
For any finite sets $A$ and $B$:
\[
|A \cup B| = |A| + |B| - |A \cap B|
\]
For probabilities: $P(A \cup B) = P(A) + P(B) - P(A \cap B)$.
\end{theorem}

Why subtract the intersection? Because if you just add $|A|$ and $|B|$, you count the overlap twice. Subtracting $|A \cap B|$ corrects for the double-counting.

\begin{theorem}[Inclusion-exclusion (three sets)]
\[
|A \cup B \cup C| = |A| + |B| + |C| - |A \cap B| - |A \cap C| - |B \cap C| + |A \cap B \cap C|
\]
\end{theorem}

\begin{theorem}[Inclusion-exclusion (general)]
For finite sets $A_1, \ldots, A_n$:
\[
\left|\bigcup_{i=1}^{n} A_i\right| = \sum_{i} |A_i| - \sum_{i < j} |A_i \cap A_j| + \sum_{i < j < k} |A_i \cap A_j \cap A_k| - \cdots
\]
The pattern alternates: add singles, subtract pairs, add triples, subtract quadruples, etc.
\end{theorem}

\subsubsection*{Conditional Probability and Independence}

\begin{definition}[Conditional probability]
If $P(B) > 0$, the probability of $A$ given that $B$ has occurred is:
\[
P(A \mid B) = \frac{P(A \cap B)}{P(B)}
\]
\end{definition}

Think of it as restricting the sample space to $B$, then asking how much of $B$ is also in $A$.

\begin{theorem}[Multiplication rule for probabilities]
\[
P(A \cap B) = P(A \mid B) \cdot P(B) = P(B \mid A) \cdot P(A)
\]
\end{theorem}

\begin{definition}[Independence]
Events $A$ and $B$ are \textbf{independent} if:
\[
P(A \cap B) = P(A) \cdot P(B)
\]
Equivalently (when $P(B) > 0$): $P(A \mid B) = P(A)$---knowing $B$ happened doesn't change the probability of $A$.
\end{definition}

\begin{warning}
Independent and disjoint are very different! If $A$ and $B$ are disjoint (no overlap), they are usually \emph{not} independent---knowing $A$ happened tells you $B$ definitely didn't happen.
\end{warning}

\subsubsection*{Bayes' Rule and Total Probability}

\begin{theorem}[Law of total probability]
If $\{B_1, \ldots, B_k\}$ is a partition of $S$ (disjoint, covering everything), then:
\[
P(A) = \sum_{i=1}^{k} P(A \mid B_i) \cdot P(B_i)
\]
\end{theorem}

This is useful when computing $P(A)$ directly is hard, but computing it conditionally on different cases is easier.

\begin{theorem}[Bayes' rule]
\[
P(B_j \mid A) = \frac{P(A \mid B_j) \cdot P(B_j)}{\sum_{i=1}^{k} P(A \mid B_i) \cdot P(B_i)}
\]
\end{theorem}

Bayes' rule ``flips'' conditional probabilities. You know $P(A \mid B)$, but you want $P(B \mid A)$. This comes up constantly: you observe evidence (tested positive, saw smoke, etc.) and want to infer the cause.

\subsubsection*{Permutations}

\begin{definition}[Permutation]
A \textbf{permutation} of a set is an arrangement of its elements in a sequence. The number of permutations of $n$ distinct objects is:
\[
n! = n \times (n-1) \times (n-2) \times \cdots \times 2 \times 1
\]
By convention, $0! = 1$.
\end{definition}

\begin{definition}[$r$-permutation]
An \textbf{$r$-permutation} of $n$ objects is an ordered arrangement of $r$ objects chosen from $n$ distinct objects. The count is:
\[
P(n, r) = \frac{n!}{(n-r)!} = n \times (n-1) \times \cdots \times (n-r+1)
\]
\end{definition}

\subsubsection*{The Pigeonhole Principle}

\begin{theorem}[Pigeonhole principle (basic)]
If $n + 1$ objects are placed into $n$ boxes, then at least one box contains at least 2 objects.
\end{theorem}

This is almost embarrassingly obvious, but it's surprisingly powerful for proving existence results.

\begin{theorem}[Pigeonhole principle (generalized)]
If $n$ objects are placed into $k$ boxes, then at least one box contains at least $\lceil n/k \rceil$ objects.
\end{theorem}

\begin{keyresult}
The pigeonhole principle guarantees existence without telling you \emph{which} box has multiple objects. It's a pure existence proof---powerful, but non-constructive.
\end{keyresult}

\subsubsection*{Derangements}

\begin{definition}[Derangement]
A \textbf{derangement} of $\{1, 2, \ldots, n\}$ is a permutation with no fixed points: $\sigma(i) \neq i$ for all $i$. The number of derangements is denoted $D_n$.
\end{definition}

\begin{theorem}[Counting derangements]
\[
D_n = n! \sum_{k=0}^{n} \frac{(-1)^k}{k!} = n! \left(1 - 1 + \frac{1}{2!} - \frac{1}{3!} + \cdots + \frac{(-1)^n}{n!}\right)
\]
\end{theorem}

\begin{keyresult}
For large $n$: $D_n \approx n!/e$. The probability that a random permutation is a derangement approaches $1/e \approx 0.368$ as $n \to \infty$. About a third of all permutations have no fixed points.
\end{keyresult}

\subsubsection*{Counting Strategies}

\begin{definition}[With vs.\ without replacement]
\begin{itemize}
  \item \textbf{With replacement:} After selecting an object, it goes back. Selections are independent.
  \item \textbf{Without replacement:} Once selected, an object is removed. Later selections have fewer choices.
\end{itemize}
\end{definition}

\begin{proposition}[Counting sequences]
From $n$ distinct elements:
\begin{itemize}
  \item Sequences of length $k$ \textbf{with replacement}: $n^k$
  \item Sequences of length $k$ \textbf{without replacement}: $P(n,k) = \frac{n!}{(n-k)!}$
\end{itemize}
\end{proposition}

\begin{strategy}[Complement counting]
Sometimes it's easier to count what you \emph{don't} want:
\[
|\text{desired}| = |\text{total}| - |\text{undesired}|
\]
Use this when the undesired outcomes have a simpler structure.
\end{strategy}

\subsection*{Worked examples}

\begin{example}[License plates]
A license plate consists of 3 letters followed by 3 digits. How many are possible?

\emph{Solution.} Using the multiplication rule:
\begin{itemize}
  \item 3 letters: $26 \times 26 \times 26 = 26^3$ choices (with replacement)
  \item 3 digits: $10 \times 10 \times 10 = 10^3$ choices
\end{itemize}
Total: $26^3 \times 10^3 = 17,576,000$ plates.
\end{example}

\begin{example}[No repeated letters]
How many 3-letter strings over $\{A, B, C, D\}$ have no repeated letters?

\emph{Solution.} This is without replacement:
\begin{itemize}
  \item First letter: 4 choices
  \item Second letter: 3 choices (can't repeat first)
  \item Third letter: 2 choices
\end{itemize}
Total: $P(4, 3) = 4 \times 3 \times 2 = 24$.
\end{example}

\begin{example}[Sum of dice]
A fair die is rolled twice. What is the probability the sum is 7?

\emph{Solution.}
\begin{itemize}
  \item Sample space: All pairs $(a, b)$ with $a, b \in \{1, 2, 3, 4, 5, 6\}$. Size: $36$.
  \item Event: pairs summing to 7. These are $(1,6), (2,5), (3,4), (4,3), (5,2), (6,1)$. Size: 6.
\end{itemize}
$P(\text{sum} = 7) = 6/36 = 1/6$.
\end{example}

\begin{example}[Complement counting]
How many 5-bit binary strings contain at least one 1?

\emph{Solution.} Direct counting is messy (exactly one 1, or two 1s, or...). Use the complement.
\begin{itemize}
  \item Total 5-bit strings: $2^5 = 32$
  \item Strings with no 1s: just $00000$, so 1
\end{itemize}
Strings with at least one 1: $32 - 1 = 31$.
\end{example}

\begin{example}[Inclusion-exclusion]
How many integers in $\{1, 2, \ldots, 100\}$ are divisible by 2 or 3?

\emph{Solution.} Let $A = \{n : 2 \mid n\}$ and $B = \{n : 3 \mid n\}$.
\begin{itemize}
  \item $|A| = \lfloor 100/2 \rfloor = 50$
  \item $|B| = \lfloor 100/3 \rfloor = 33$
  \item $|A \cap B| = |\{n : 6 \mid n\}| = \lfloor 100/6 \rfloor = 16$
\end{itemize}
$|A \cup B| = 50 + 33 - 16 = 67$.
\end{example}

\begin{example}[Pigeonhole: birth months]
Prove: Among any 13 people, at least two share a birth month.

\emph{Proof.} There are 12 months (boxes) and 13 people (objects). By the pigeonhole principle, at least one month contains at least 2 people. \qed
\end{example}

\begin{example}[Pigeonhole: remainders]
Prove: In any set of 6 integers, two have the same remainder when divided by 5.

\emph{Proof.} Remainders mod 5 are in $\{0, 1, 2, 3, 4\}$ (5 boxes). With 6 integers (objects), at least two land in the same box. \qed
\end{example}

\begin{example}[Adjacent seating]
How many ways can 8 people sit in a row if Alice and Bob must sit together?

\emph{Solution.} Treat Alice-Bob as a single ``super-person.'' Then:
\begin{itemize}
  \item Arrange 7 objects: $7!$ ways
  \item Alice and Bob can swap within their block: 2 ways
\end{itemize}
Total: $7! \times 2 = 5040 \times 2 = 10080$.
\end{example}

\begin{example}[Non-adjacent seating]
How many ways can 8 people sit in a row if Alice and Bob must NOT sit together?

\emph{Solution.} Use complement counting.
\begin{itemize}
  \item Total arrangements: $8! = 40320$
  \item Arrangements where they sit together: $10080$ (from previous)
\end{itemize}
Answer: $40320 - 10080 = 30240$.
\end{example}

\begin{example}[Pigeonhole: geometry]
Prove: Among any 5 points in a unit square, at least two are within distance $\sqrt{2}/2$ of each other.

\emph{Proof.} Divide the unit square into 4 smaller squares of side $1/2$. By pigeonhole, at least two of the 5 points lie in the same small square. The maximum distance between two points in a square of side $1/2$ is the diagonal: $\sqrt{2}/2$. \qed
\end{example}

\begin{example}[Conditional probability]
Two cards are drawn without replacement from a standard deck. Given that the first is an ace, what's the probability the second is also an ace?

\emph{Solution.} After drawing an ace, the deck has 51 cards remaining, 3 of which are aces.
\[
P(\text{2nd ace} \mid \text{1st ace}) = \frac{3}{51} = \frac{1}{17}
\]
\end{example}

\begin{example}[Bayes' rule: factory machines]
A factory has two machines. $M_1$ produces 70\% of items with 2\% defect rate; $M_2$ produces 30\% with 5\% defect rate. If an item is defective, what's the probability it came from $M_2$?

\emph{Solution.} First, find $P(\text{defective})$:
\[
P(D) = P(D \mid M_1)P(M_1) + P(D \mid M_2)P(M_2) = 0.02 \cdot 0.7 + 0.05 \cdot 0.3 = 0.029
\]

Then apply Bayes:
\[
P(M_2 \mid D) = \frac{P(D \mid M_2)P(M_2)}{P(D)} = \frac{0.05 \cdot 0.3}{0.029} = \frac{0.015}{0.029} \approx 0.517
\]

A defective item is slightly more likely to come from $M_2$, even though $M_2$ produces fewer items overall. The higher defect rate more than compensates.
\end{example}

\begin{example}[Computing derangements]
Compute $D_4$.

\emph{Solution.} Using the formula:
\[
D_4 = 4! \left(1 - 1 + \frac{1}{2} - \frac{1}{6} + \frac{1}{24}\right) = 24 \cdot \frac{9}{24} = 9
\]

We can verify: the derangements of $\{1,2,3,4\}$ are permutations where no element is in its original position. They are: 2143, 2341, 2413, 3142, 3412, 3421, 4123, 4312, 4321. Indeed, 9.
\end{example}

\begin{commonmistake}
\textbf{Overcounting.} Make sure you're not counting the same configuration multiple times. Ask:
\begin{itemize}
  \item Does order matter? (permutation vs.\ combination)
  \item Are objects distinguishable?
  \item Are positions/boxes distinguishable?
\end{itemize}
\end{commonmistake}

\begin{commonmistake}
\textbf{Misapplying the multiplication rule.} The rule requires that choices at each step are independent of previous choices. If earlier choices constrain later options, you must account for this carefully.
\end{commonmistake}

\begin{goingdeeper}[Going Deeper: The Algebra of Types]
The counting rules---multiplication and addition---have a surprising connection to types in programming. This reveals why these rules are fundamental.

For more detail, see the Category Theory Companion, Weeks 4--5.

\subsubsection*{Types Have Sizes}

In programming, a type is a set of values:
\begin{center}
\begin{tabular}{lcc}
\textbf{Type} & \textbf{Description} & \textbf{Size} \\
\hline
\texttt{Void} & empty type & 0 \\
\texttt{Unit} or \texttt{()} & single value & 1 \\
\texttt{Bool} & \texttt{True} or \texttt{False} & 2 \\
\end{tabular}
\end{center}

\subsubsection*{Products and Sums}

When we combine types:
\begin{itemize}
  \item \textbf{Product type} $(A, B)$: $|A \times B| = |A| \times |B|$
  \item \textbf{Sum type} \texttt{Either A B}: $|A + B| = |A| + |B|$
\end{itemize}

This is exactly the multiplication and addition rules! The type \texttt{(Bool, Bool)} has $2 \times 2 = 4$ values. The type \texttt{Either Bool ()} has $2 + 1 = 3$ values.

\subsubsection*{Function Types as Exponentials}

Function types $A \to B$ have $|B|^{|A|}$ values. Why? For each input in $A$, you choose one output in $B$. That's $|B|$ choices for each of $|A|$ inputs, so $|B|^{|A|}$ total functions.

\subsubsection*{Exercises}

\begin{enumerate}
  \item How many values does \texttt{(Bool, Bool, Bool)} have?
  \item How many values does \texttt{Either Bool Bool} have? Different from \texttt{(Bool, Bool)}?
  \item If $|A| = 3$ and $|B| = 4$, what are $|A \times B|$ and $|A + B|$?
  \item Verify: there are $3^2 = 9$ functions from \texttt{Bool} to $\{1, 2, 3\}$.
\end{enumerate}
\end{goingdeeper}

\subsection*{Practice}
\begin{enumerate}
  \item A fair die is rolled twice. What is the probability the sum is 7?

  \item How many 5-bit binary strings contain at least one 1?

  \item Use inclusion--exclusion to count integers in $\{1, \ldots, 100\}$ divisible by 2 or 3.

  \item Use the pigeonhole principle to show that among 13 people, two share a birth month.

  \item How many 4-digit PINs (digits 0--9) have no repeated digits?

  \item How many ways can 6 books be arranged on a shelf if two specific books must be at the ends?

  \item How many bit strings of length 8 start with 1 or end with 00?

  \item Prove: Among any 10 integers, two have a difference divisible by 9.

  \item A restaurant offers 3 appetizers, 5 mains, and 2 desserts. How many 3-course meals are possible?

  \item How many permutations of ABCDEF contain ABC as a consecutive substring?

  \item Use inclusion-exclusion to count integers in $\{1, \ldots, 1000\}$ divisible by 2, 3, or 5.

  \item Compute $D_5$ (derangements of 5 elements).

  \item Five friends exchange gifts so no one receives their own. How many ways?

  \item Two dice are rolled. Let $A$ = ``sum is even'' and $B$ = ``sum $\geq 10$''. Compute $P(A \mid B)$ and determine if $A, B$ are independent.

  \item A box has 3 fair coins and 1 double-headed coin. A coin is chosen randomly and flipped. If heads, what's the probability it was double-headed?

  \item A disease test has sensitivity 0.95 and false positive rate 0.02. If 1\% of the population has the disease, what's the probability someone who tests positive actually has it?
\end{enumerate}
